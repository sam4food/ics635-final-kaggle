{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 91844,
          "databundleVersionId": 11361821,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Credit: https://www.kaggle.com/code/jocelyndumlao/birdclef-2025-inference-w-simplecnn-spectrogram <br>\n",
        "Changed CNN architecture."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-20T11:16:58.659485Z",
          "iopub.execute_input": "2025-04-20T11:16:58.659795Z",
          "iopub.status.idle": "2025-04-20T11:16:58.66556Z",
          "shell.execute_reply.started": "2025-04-20T11:16:58.659769Z",
          "shell.execute_reply": "2025-04-20T11:16:58.663784Z"
        },
        "id": "fLlGjIKE6PHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import gc\n",
        "import dataclasses\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from typing import Optional, Callable, Tuple, List\n",
        "import traceback  # Import traceback module"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-20T11:18:03.957842Z",
          "iopub.execute_input": "2025-04-20T11:18:03.958206Z",
          "iopub.status.idle": "2025-04-20T11:18:05.859897Z",
          "shell.execute_reply.started": "2025-04-20T11:18:03.958171Z",
          "shell.execute_reply": "2025-04-20T11:18:05.858459Z"
        },
        "trusted": true,
        "id": "bBQRJt926PHi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = \"/kaggle/input/birdclef-2025/test_soundscapes\"\n",
        "submission = \"/kaggle/input/birdclef-2025/sample_submission.csv\"\n",
        "train_csv = \"/kaggle/input/birdclef-2025/train.csv\"\n",
        "taxonomy_csv = \"/kaggle/input/birdclef-2025/taxonomy.csv\"\n",
        "\n",
        "transform: Optional[Callable] = None  # Type hint for transform\n",
        "audio_transform: Optional[Callable] = None # Type hint for audio_transform\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class AudioParam:\n",
        "    SR: int = 32_000  # Sample rate\n",
        "    NFFT: int = 2048  # Number of FFT points\n",
        "    NMEL: int = 128   # Number of Mel bands\n",
        "    FMAX: int = 16_000 # Maximum frequency\n",
        "    FMIN: int = 20   # Minimum frequency\n",
        "    HOP_LENGTH: int = NFFT // 4  # Hop length\n",
        "\n",
        "audio_param = AudioParam()\n",
        "\n",
        "# Load submission CSV to get class names\n",
        "try:\n",
        "    sub_csv = pd.read_csv(submission)\n",
        "    idx2cls = sub_csv.columns.drop(\"row_id\").tolist()  # List of bird species (class names)\n",
        "    cls2idx = {c: i for i, c in enumerate(idx2cls)} # Class name to index mapping\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: sample_submission.csv not found! {e}\")\n",
        "    idx2cls = [] # Provide a default for testing, but the code will likely fail\n",
        "    cls2idx = {}\n",
        "\n",
        "\n",
        "DEBUG = True # Enable Debugging\n",
        "file_names = [os.path.join(test_data, fp) for fp in os.listdir(test_data) if fp.endswith(\".ogg\")]\n",
        "\n",
        "# Use a single file for debugging.  This makes the matrix dimension calculations easier.\n",
        "if len(file_names) == 0:\n",
        "    file_names = [\n",
        "        \"/kaggle/input/birdclef-2025/train_soundscapes/H02_20230420_074000.ogg\",\n",
        "    ]\n",
        "    DEBUG = True\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T11:18:05.860965Z",
          "iopub.execute_input": "2025-04-20T11:18:05.86145Z",
          "iopub.status.idle": "2025-04-20T11:18:05.878856Z",
          "shell.execute_reply.started": "2025-04-20T11:18:05.861409Z",
          "shell.execute_reply": "2025-04-20T11:18:05.877481Z"
        },
        "id": "Jb5N27QU6PHj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        # Convolutional feature extractor\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        # Global pooling + classifier\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # collapse H×W → 1×1\n",
        "        self.dropout     = nn.Dropout(0.5)\n",
        "        self.classifier  = nn.Linear(256, num_classes)\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (B, 1, H, W)\n",
        "        x = self.features(x)               # → (B, 256, H', W')\n",
        "        x = self.global_pool(x)            # → (B, 256, 1, 1)\n",
        "        x = torch.flatten(x, 1)            # → (B, 256)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)             # → (B, num_classes)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T11:18:05.881303Z",
          "iopub.execute_input": "2025-04-20T11:18:05.881708Z",
          "iopub.status.idle": "2025-04-20T11:18:05.895093Z",
          "shell.execute_reply.started": "2025-04-20T11:18:05.881669Z",
          "shell.execute_reply": "2025-04-20T11:18:05.893713Z"
        },
        "id": "4dOR152c6PHj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = ImprovedCNN(num_classes=len(idx2cls))\n",
        "model.eval()\n",
        "\n",
        "def pipeline(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Converts audio data to a mel spectrogram and then to a dB scale.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        mels = librosa.feature.melspectrogram(\n",
        "            y=x,\n",
        "            sr=audio_param.SR,\n",
        "            n_fft=audio_param.NFFT,\n",
        "            n_mels=audio_param.NMEL,\n",
        "            fmax=audio_param.FMAX,\n",
        "            fmin=audio_param.FMIN,\n",
        "            hop_length=audio_param.HOP_LENGTH,\n",
        "        )\n",
        "        db_map = librosa.power_to_db(mels, ref=np.max)\n",
        "        db_map = (db_map + 80) / (80 + 1e-6)  # Normalize to [0, 1] - Added small constant\n",
        "        if np.isnan(db_map).any():\n",
        "            print(\"Warning: NaN values detected in db_map!\")\n",
        "            db_map = np.nan_to_num(db_map) #Replace with 0\n",
        "\n",
        "        return db_map[None, :, :]  # Add a channel dimension (1, height, width)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in pipeline: {e}\")\n",
        "        return np.zeros((1, audio_param.NMEL, 1)) # return a zero array\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T11:18:05.896394Z",
          "iopub.execute_input": "2025-04-20T11:18:05.896842Z",
          "iopub.status.idle": "2025-04-20T11:18:05.932015Z",
          "shell.execute_reply.started": "2025-04-20T11:18:05.896803Z",
          "shell.execute_reply": "2025-04-20T11:18:05.9303Z"
        },
        "id": "9ePx9oQx6PHk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(fp: str) -> Tuple[np.ndarray, List[str]]:\n",
        "    \"\"\"\n",
        "    Predicts bird calls in a given audio file.\n",
        "\n",
        "    Args:\n",
        "        fp (str): File path of the audio file.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, List[str]]: Tuple containing the model output and the list of row IDs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        x, _ = librosa.load(fp, sr=audio_param.SR)  # Load the audio file.\n",
        "\n",
        "        if x.size == 0:\n",
        "            print(f\"Warning: Audio file {fp} is empty!\")\n",
        "            return np.array([]), [] #return empty arrays\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file {fp}: {e}\")\n",
        "        return np.array([]), []\n",
        "\n",
        "    # Number of 5-second segments\n",
        "    num_segments = int(np.floor(len(x) / audio_param.SR / 5))\n",
        "    all_outs = []\n",
        "    all_row_ids = []\n",
        "    for i in range(num_segments):\n",
        "        start = i * audio_param.SR * 5\n",
        "        end = (i + 1) * audio_param.SR * 5\n",
        "        segment = x[start:end]\n",
        "\n",
        "\n",
        "        if audio_transform is not None:\n",
        "            try:\n",
        "                segment = audio_transform(sample=segment, sample_rate=audio_param.SR) #Apply audio transform\n",
        "            except Exception as e:\n",
        "                print(f\"Audio Transform Failed {e}\")\n",
        "\n",
        "        try:\n",
        "            segment = pipeline(segment)  #Convert waveform to mel spectrogram.\n",
        "        except Exception as e:\n",
        "            print(f\"Pipeline failed {e}\")\n",
        "            continue\n",
        "\n",
        "        if transform is not None:\n",
        "            try:\n",
        "                segment = transform(image=segment)[\"image\"] #Apply image transform.\n",
        "            except Exception as e:\n",
        "                print(f\"Transform failed {e}\")\n",
        "                continue\n",
        "\n",
        "        try:\n",
        "            segment = torch.from_numpy(segment).float().unsqueeze(0)  # Convert to tensor and add batch dimension.\n",
        "            out = model(segment).sigmoid().detach().cpu().numpy() # Get the model output.\n",
        "            all_outs.append(out[0])\n",
        "\n",
        "            fp_name = os.path.basename(fp).split(\".\")[0] #Extract the base filename.\n",
        "            row_id = f\"{fp_name}_{(i + 1) * 5}\" #Create row IDs.  Correct the slice name\n",
        "            all_row_ids.append(row_id)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during processing of segment {i} in {fp}: {e}  {traceback.format_exc()}\") #Print trace\n",
        "\n",
        "    return np.array(all_outs), all_row_ids # return all values\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T11:18:05.933233Z",
          "iopub.execute_input": "2025-04-20T11:18:05.933594Z",
          "iopub.status.idle": "2025-04-20T11:18:05.944818Z",
          "shell.execute_reply.started": "2025-04-20T11:18:05.933562Z",
          "shell.execute_reply": "2025-04-20T11:18:05.943438Z"
        },
        "id": "8YmnhDGg6PHl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "row_id = []\n",
        "matrix = []\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    for fp_idx, (fp) in enumerate(file_names):\n",
        "        try:\n",
        "            out, rid = predict(fp)\n",
        "            if len(rid) > 0:\n",
        "                row_id.extend(rid)\n",
        "                matrix.extend(out)\n",
        "            else:\n",
        "                print(f\"Warning: No predictions generated for file: {fp}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run predict for file {fp} {e}\")\n",
        "        gc.collect() #Collect after each file\n",
        "        print(f\"Finished {fp_idx+1}/{len(file_names)}\")\n",
        "\n",
        "try:\n",
        "    matrix = np.array(matrix).reshape(-1, len(idx2cls))\n",
        "    row_id = np.array(row_id).reshape(-1, 1)\n",
        "    matrix = np.hstack([row_id, matrix])\n",
        "\n",
        "    # Create a Pandas DataFrame from the results.\n",
        "    sub = pd.DataFrame(matrix, columns=[\"row_id\", *idx2cls])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "\n",
        "    print(sub.head())\n",
        "except Exception as e:\n",
        "    print(f\"Error creating submission file {e}\")\n",
        "\n",
        "print(\"Finished!\")\n",
        "gc.collect()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T11:18:05.945807Z",
          "iopub.execute_input": "2025-04-20T11:18:05.94612Z",
          "iopub.status.idle": "2025-04-20T11:18:07.992182Z",
          "shell.execute_reply.started": "2025-04-20T11:18:05.946091Z",
          "shell.execute_reply": "2025-04-20T11:18:07.991454Z"
        },
        "id": "OfIDiOhu6PHm"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}