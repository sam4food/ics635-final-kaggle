{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 91844,
          "databundleVersionId": 11361821,
          "sourceType": "competition"
        },
        {
          "sourceId": 11520367,
          "sourceType": "datasetVersion",
          "datasetId": 7225109
        },
        {
          "sourceId": 11524118,
          "sourceType": "datasetVersion",
          "datasetId": 7227419
        },
        {
          "sourceId": 11570930,
          "sourceType": "datasetVersion",
          "datasetId": 7254241
        },
        {
          "sourceId": 11570971,
          "sourceType": "datasetVersion",
          "datasetId": 7254261
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNet B0 [Inference] vSubmission2"
      ],
      "metadata": {
        "id": "GROUGCPsIcDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing"
      ],
      "metadata": {
        "id": "89Vsjq4aIk5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "import logging\n",
        "import time\n",
        "import math\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:07.737294Z",
          "iopub.execute_input": "2025-04-26T03:20:07.738199Z",
          "iopub.status.idle": "2025-04-26T03:20:13.584997Z",
          "shell.execute_reply.started": "2025-04-26T03:20:07.738148Z",
          "shell.execute_reply": "2025-04-26T03:20:13.583563Z"
        },
        "id": "pql4rVJGIcDp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "LJFp3kwWIlxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "\n",
        "    test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
        "    submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
        "    taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
        "    model_path = '/kaggle/input/efficientnet-sub-vs2'\n",
        "\n",
        "    # Audio parameters\n",
        "    FS = 32000\n",
        "    WINDOW_SIZE = 5\n",
        "\n",
        "    # Mel spectrogram parameters\n",
        "    N_FFT = 1034\n",
        "    HOP_LENGTH = 64\n",
        "    N_MELS = 136\n",
        "    FMIN = 20\n",
        "    FMAX = 16000\n",
        "    TARGET_SHAPE = (256, 256)\n",
        "\n",
        "    model_name = 'efficientnet_b0'\n",
        "    in_channels = 1\n",
        "    device = 'cpu'\n",
        "\n",
        "    # Inference parameters\n",
        "    batch_size = 16\n",
        "    use_tta = False\n",
        "    tta_count = 3\n",
        "    threshold = 0.5\n",
        "\n",
        "    use_specific_folds = False  # If False, use all found models\n",
        "    folds = [0, 1]  # Used only if use_specific_folds is True\n",
        "\n",
        "    debug = False\n",
        "    debug_count = 3\n",
        "\n",
        "cfg = CFG()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:13.586627Z",
          "iopub.execute_input": "2025-04-26T03:20:13.587056Z",
          "iopub.status.idle": "2025-04-26T03:20:13.59335Z",
          "shell.execute_reply.started": "2025-04-26T03:20:13.587021Z",
          "shell.execute_reply": "2025-04-26T03:20:13.592051Z"
        },
        "id": "f3Dyfo19IcDq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using device: {cfg.device}\")\n",
        "print(f\"Loading taxonomy data...\")\n",
        "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
        "species_ids = taxonomy_df['primary_label'].tolist()\n",
        "num_classes = len(species_ids)\n",
        "print(f\"Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:13.59454Z",
          "iopub.execute_input": "2025-04-26T03:20:13.594902Z",
          "iopub.status.idle": "2025-04-26T03:20:13.625844Z",
          "shell.execute_reply.started": "2025-04-26T03:20:13.594873Z",
          "shell.execute_reply": "2025-04-26T03:20:13.624535Z"
        },
        "id": "LRrFhpSBIcDq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "RtB9ZdpWInE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeM(nn.Module):\n",
        "    def __init__(self, p: float = 3.0, eps: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, H, W)\n",
        "        x = x.clamp(min=self.eps).pow(self.p)\n",
        "        x = F.adaptive_avg_pool2d(x, 1)\n",
        "        return x.pow(1.0 / self.p).view(x.size(0), -1)  # (B, C)\n",
        "\n",
        "class BirdCLEFModel(nn.Module):\n",
        "    def __init__(self, cfg, num_class):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        # number of species\n",
        "        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
        "        cfg.num_classes = len(taxonomy_df)\n",
        "\n",
        "        # backbone (EfficientNet / ResNet / etc)\n",
        "        self.backbone = timm.create_model(\n",
        "            cfg.model_name,\n",
        "            in_chans=cfg.in_channels,\n",
        "            drop_rate=0.2,\n",
        "            drop_path_rate=0.2\n",
        "        )\n",
        "\n",
        "        # strip off original head & get feat dim\n",
        "        if 'efficientnet' in cfg.model_name:\n",
        "            feat_dim = self.backbone.classifier.in_features\n",
        "            self.backbone.classifier = nn.Identity()\n",
        "        elif 'resnet' in cfg.model_name:\n",
        "            feat_dim = self.backbone.fc.in_features\n",
        "            self.backbone.fc = nn.Identity()\n",
        "        else:\n",
        "            feat_dim = self.backbone.get_classifier().in_features\n",
        "            self.backbone.reset_classifier(0, '')\n",
        "\n",
        "        # GeM pooling\n",
        "        self.pool = GeM()\n",
        "\n",
        "        # simple 2-layer head\n",
        "        hidden_dim = feat_dim // 2\n",
        "        dr = getattr(cfg, 'dropout_rate', 0.5)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dr),\n",
        "            nn.Linear(feat_dim, hidden_dim, bias=False),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dr),\n",
        "            nn.Linear(hidden_dim, cfg.num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x, targets=None):\n",
        "        # optional mixup\n",
        "        if self.training and self.mixup_enabled and targets is not None:\n",
        "            x, ta, tb, lam = self._mixup(x, targets)\n",
        "        else:\n",
        "            ta = tb = lam = None\n",
        "\n",
        "        # backbone → feature map or vector\n",
        "        feats = self.backbone(x)\n",
        "        if isinstance(feats, dict):\n",
        "            feats = feats['features']\n",
        "\n",
        "        # if spatial map, pool to (B, feat_dim)\n",
        "        if feats.ndim == 4:\n",
        "            feats = self.pool(feats)\n",
        "\n",
        "        # head → logits\n",
        "        logits = self.head(feats)\n",
        "\n",
        "        # mixup-aware loss\n",
        "        if self.training and self.mixup_enabled and targets is not None:\n",
        "            loss = lam * F.binary_cross_entropy_with_logits(logits, ta) + \\\n",
        "                   (1 - lam) * F.binary_cross_entropy_with_logits(logits, tb)\n",
        "            return logits, loss\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:13.627182Z",
          "iopub.execute_input": "2025-04-26T03:20:13.627593Z",
          "iopub.status.idle": "2025-04-26T03:20:13.643579Z",
          "shell.execute_reply.started": "2025-04-26T03:20:13.627549Z",
          "shell.execute_reply": "2025-04-26T03:20:13.641503Z"
        },
        "id": "YCCr9x12IcDq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def audio2melspec(audio_data, cfg):\n",
        "    \"\"\"Convert audio data to mel spectrogram\"\"\"\n",
        "    if np.isnan(audio_data).any():\n",
        "        mean_signal = np.nanmean(audio_data)\n",
        "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
        "\n",
        "    mel_spec = librosa.feature.melspectrogram(\n",
        "        y=audio_data,\n",
        "        sr=cfg.FS,\n",
        "        n_fft=cfg.N_FFT,\n",
        "        hop_length=cfg.HOP_LENGTH,\n",
        "        n_mels=cfg.N_MELS,\n",
        "        fmin=cfg.FMIN,\n",
        "        fmax=cfg.FMAX,\n",
        "        power=2.0\n",
        "    )\n",
        "\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
        "\n",
        "    return mel_spec_norm\n",
        "\n",
        "def process_audio_segment(audio_data, cfg):\n",
        "    \"\"\"Process audio segment to get mel spectrogram\"\"\"\n",
        "    if len(audio_data) < cfg.FS * cfg.WINDOW_SIZE:\n",
        "        audio_data = np.pad(audio_data,\n",
        "                          (0, cfg.FS * cfg.WINDOW_SIZE - len(audio_data)),\n",
        "                          mode='constant')\n",
        "\n",
        "    mel_spec = audio2melspec(audio_data, cfg)\n",
        "\n",
        "    # Resize if needed\n",
        "    if mel_spec.shape != cfg.TARGET_SHAPE:\n",
        "        mel_spec = cv2.resize(mel_spec, cfg.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    return mel_spec.astype(np.float32)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:13.646959Z",
          "iopub.execute_input": "2025-04-26T03:20:13.647356Z",
          "iopub.status.idle": "2025-04-26T03:20:13.669696Z",
          "shell.execute_reply.started": "2025-04-26T03:20:13.647319Z",
          "shell.execute_reply": "2025-04-26T03:20:13.668433Z"
        },
        "id": "7o6gKu6AIcDq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def find_model_files(cfg):\n",
        "    \"\"\"\n",
        "    Find all .pth model files in the specified model directory\n",
        "    \"\"\"\n",
        "    model_files = []\n",
        "\n",
        "    model_dir = Path(cfg.model_path)\n",
        "\n",
        "    for path in model_dir.glob('**/*.pth'):\n",
        "        model_files.append(str(path))\n",
        "\n",
        "    return model_files\n",
        "\n",
        "def load_models(cfg, num_classes):\n",
        "    \"\"\"\n",
        "    Load all found model files and prepare them for ensemble\n",
        "    \"\"\"\n",
        "    models = []\n",
        "\n",
        "    model_files = find_model_files(cfg)\n",
        "\n",
        "    if not model_files:\n",
        "        print(f\"Warning: No model files found under {cfg.model_path}!\")\n",
        "        return models\n",
        "\n",
        "    print(f\"Found a total of {len(model_files)} model files.\")\n",
        "\n",
        "    if cfg.use_specific_folds:\n",
        "        filtered_files = []\n",
        "        for fold in cfg.folds:\n",
        "            fold_files = [f for f in model_files if f\"fold{fold}\" in f]\n",
        "            filtered_files.extend(fold_files)\n",
        "        model_files = filtered_files\n",
        "        print(f\"Using {len(model_files)} model files for the specified folds ({cfg.folds}).\")\n",
        "\n",
        "    for model_path in model_files:\n",
        "        try:\n",
        "            print(f\"Loading model: {model_path}\")\n",
        "            checkpoint = torch.load(model_path, map_location=torch.device(cfg.device))\n",
        "\n",
        "            model = BirdCLEFModel(cfg, num_classes)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            model = model.to(cfg.device)\n",
        "            model.eval()\n",
        "\n",
        "            models.append(model)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {model_path}: {e}\")\n",
        "\n",
        "    return models\n",
        "\n",
        "def predict_on_spectrogram(audio_path, models, cfg, species_ids):\n",
        "    \"\"\"Process a single audio file and predict species presence for each 5-second segment\"\"\"\n",
        "    predictions = []\n",
        "    row_ids = []\n",
        "    soundscape_id = Path(audio_path).stem\n",
        "\n",
        "    try:\n",
        "        print(f\"Processing {soundscape_id}\")\n",
        "        audio_data, _ = librosa.load(audio_path, sr=cfg.FS)\n",
        "\n",
        "        total_segments = int(len(audio_data) / (cfg.FS * cfg.WINDOW_SIZE))\n",
        "\n",
        "        for segment_idx in range(total_segments):\n",
        "            start_sample = segment_idx * cfg.FS * cfg.WINDOW_SIZE\n",
        "            end_sample = start_sample + cfg.FS * cfg.WINDOW_SIZE\n",
        "            segment_audio = audio_data[start_sample:end_sample]\n",
        "\n",
        "            end_time_sec = (segment_idx + 1) * cfg.WINDOW_SIZE\n",
        "            row_id = f\"{soundscape_id}_{end_time_sec}\"\n",
        "            row_ids.append(row_id)\n",
        "\n",
        "            if cfg.use_tta:\n",
        "                all_preds = []\n",
        "\n",
        "                for tta_idx in range(cfg.tta_count):\n",
        "                    mel_spec = process_audio_segment(segment_audio, cfg)\n",
        "                    mel_spec = apply_tta(mel_spec, tta_idx)\n",
        "\n",
        "                    mel_spec = torch.tensor(mel_spec, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "                    mel_spec = mel_spec.to(cfg.device)\n",
        "\n",
        "                    if len(models) == 1:\n",
        "                        with torch.no_grad():\n",
        "                            outputs = models[0](mel_spec)\n",
        "                            probs = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
        "                            all_preds.append(probs)\n",
        "                    else:\n",
        "                        segment_preds = []\n",
        "                        for model in models:\n",
        "                            with torch.no_grad():\n",
        "                                outputs = model(mel_spec)\n",
        "                                probs = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
        "                                segment_preds.append(probs)\n",
        "\n",
        "                        avg_preds = np.mean(segment_preds, axis=0)\n",
        "                        all_preds.append(avg_preds)\n",
        "\n",
        "                final_preds = np.mean(all_preds, axis=0)\n",
        "            else:\n",
        "                mel_spec = process_audio_segment(segment_audio, cfg)\n",
        "\n",
        "                mel_spec = torch.tensor(mel_spec, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "                mel_spec = mel_spec.to(cfg.device)\n",
        "\n",
        "                if len(models) == 1:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = models[0](mel_spec)\n",
        "                        final_preds = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
        "                else:\n",
        "                    segment_preds = []\n",
        "                    for model in models:\n",
        "                        with torch.no_grad():\n",
        "                            outputs = model(mel_spec)\n",
        "                            probs = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
        "                            segment_preds.append(probs)\n",
        "\n",
        "                    final_preds = np.mean(segment_preds, axis=0)\n",
        "\n",
        "            predictions.append(final_preds)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "\n",
        "    return row_ids, predictions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:13.671445Z",
          "iopub.execute_input": "2025-04-26T03:20:13.671849Z",
          "iopub.status.idle": "2025-04-26T03:20:13.70054Z",
          "shell.execute_reply.started": "2025-04-26T03:20:13.671802Z",
          "shell.execute_reply": "2025-04-26T03:20:13.698894Z"
        },
        "id": "H0rC_AP7IcDr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_tta(spec, tta_idx):\n",
        "    \"\"\"Apply test-time augmentation\"\"\"\n",
        "    if tta_idx == 0:\n",
        "        # Original spectrogram\n",
        "        return spec\n",
        "    elif tta_idx == 1:\n",
        "        # Time shift (horizontal flip)\n",
        "        return np.flip(spec, axis=1)\n",
        "    elif tta_idx == 2:\n",
        "        # Frequency shift (vertical flip)\n",
        "        return np.flip(spec, axis=0)\n",
        "    else:\n",
        "        return spec\n",
        "\n",
        "def run_inference(cfg, models, species_ids):\n",
        "    \"\"\"Run inference on all test soundscapes\"\"\"\n",
        "    test_files = list(Path(cfg.test_soundscapes).glob('*.ogg'))\n",
        "\n",
        "    if cfg.debug:\n",
        "        print(f\"Debug mode enabled, using only {cfg.debug_count} files\")\n",
        "        test_files = test_files[:cfg.debug_count]\n",
        "\n",
        "    print(f\"Found {len(test_files)} test soundscapes\")\n",
        "\n",
        "    all_row_ids = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for audio_path in tqdm(test_files):\n",
        "        row_ids, predictions = predict_on_spectrogram(str(audio_path), models, cfg, species_ids)\n",
        "        all_row_ids.extend(row_ids)\n",
        "        all_predictions.extend(predictions)\n",
        "\n",
        "    return all_row_ids, all_predictions\n",
        "\n",
        "def create_submission(row_ids, predictions, species_ids, cfg):\n",
        "    \"\"\"Create submission dataframe\"\"\"\n",
        "    print(\"Creating submission dataframe...\")\n",
        "\n",
        "    submission_dict = {'row_id': row_ids}\n",
        "\n",
        "    for i, species in enumerate(species_ids):\n",
        "        submission_dict[species] = [pred[i] for pred in predictions]\n",
        "\n",
        "    submission_df = pd.DataFrame(submission_dict)\n",
        "\n",
        "    submission_df.set_index('row_id', inplace=True)\n",
        "\n",
        "    sample_sub = pd.read_csv(cfg.submission_csv, index_col='row_id')\n",
        "\n",
        "    missing_cols = set(sample_sub.columns) - set(submission_df.columns)\n",
        "    if missing_cols:\n",
        "        print(f\"Warning: Missing {len(missing_cols)} species columns in submission\")\n",
        "        for col in missing_cols:\n",
        "            submission_df[col] = 0.0\n",
        "\n",
        "    submission_df = submission_df[sample_sub.columns]\n",
        "\n",
        "    submission_df = submission_df.reset_index()\n",
        "\n",
        "    return submission_df\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:13.702112Z",
          "iopub.execute_input": "2025-04-26T03:20:13.702728Z",
          "iopub.status.idle": "2025-04-26T03:20:13.72352Z",
          "shell.execute_reply.started": "2025-04-26T03:20:13.702689Z",
          "shell.execute_reply": "2025-04-26T03:20:13.721836Z"
        },
        "id": "mOfoS5ytIcDr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    start_time = time.time()\n",
        "    print(\"Starting BirdCLEF-2025 inference...\")\n",
        "    print(f\"TTA enabled: {cfg.use_tta} (variations: {cfg.tta_count if cfg.use_tta else 0})\")\n",
        "\n",
        "    models = load_models(cfg, num_classes)\n",
        "\n",
        "    if not models:\n",
        "        print(\"No models found! Please check model paths.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Model usage: {'Single model' if len(models) == 1 else f'Ensemble of {len(models)} models'}\")\n",
        "\n",
        "    row_ids, predictions = run_inference(cfg, models, species_ids)\n",
        "\n",
        "    submission_df = create_submission(row_ids, predictions, species_ids, cfg)\n",
        "\n",
        "    submission_path = 'submission.csv'\n",
        "    submission_df.to_csv(submission_path, index=False)\n",
        "    print(f\"Submission saved to {submission_path}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Inference completed in {(end_time - start_time)/60:.2f} minutes\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:13.724748Z",
          "iopub.execute_input": "2025-04-26T03:20:13.726437Z",
          "iopub.status.idle": "2025-04-26T03:20:13.749566Z",
          "shell.execute_reply.started": "2025-04-26T03:20:13.726347Z",
          "shell.execute_reply": "2025-04-26T03:20:13.748405Z"
        },
        "id": "2br1MXqGIcDs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-26T03:20:13.750565Z",
          "iopub.execute_input": "2025-04-26T03:20:13.750872Z",
          "iopub.status.idle": "2025-04-26T03:20:14.144568Z",
          "shell.execute_reply.started": "2025-04-26T03:20:13.750832Z",
          "shell.execute_reply": "2025-04-26T03:20:14.143511Z"
        },
        "id": "YJij57F9IcDs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "NgIsejg_IcDs"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}